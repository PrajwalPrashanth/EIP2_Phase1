# EIP - 2 | Assignment 2

#### Prajwal Prashanth | prajwal.prashanth22@gmail.com | Batch-4

___

### Neural Network calculations Step wise both forward and backward propagation



**Step - 0 : ** Read input and output

| x    |      |      |      | wh   |      |      | bh   |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1    | 0    | 1    | 0    |      |      |      |      |      |                    |      |      |                          |      |      |      |      |        | 1    |      |
| 1    | 0    | 1    | 1    |      |      |      |      |      |                    |      |      |                          |      |      |      |      |        | 1    |      |
| 0    | 1    | 0    | 1    |      |      |      |      |      |                    |      |      |                          |      |      |      |      |        | 0    |      |

___



**Step - 1 :** Initialize weights and biases with random values (There are methods to initialize weights and biases but for now initialize with random values)

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  |                    |      |      |                          |      |      | 0.23 | 0.49 |        | 1    |      |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      |                    |      |      |                          |      |      | 0.54 |      |        | 1    |      |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      |                    |      |      |                          |      |      | 0.82 |      |        | 0    |      |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |      |

___



**Step - 2 :**  Calculate hidden layer input : **_hidden_layer_input = matrix_dot_product(X,wh)+bh_** 

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 |                          |      |      | 0.23 | 0.49 |        | 1    |      |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 |                          |      |      | 0.54 |      |        | 1    |      |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 |                          |      |      | 0.82 |      |        | 0    |      |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |      |

___



**Step - 3 :** Perform non-linear transformation on hidden linear input  : **_hidden_layer_activations = sigmoid(_hidden_layer_input)**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.23 | 0.49 |        | 1    |      |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.54 |      |        | 1    |      |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.82 |      |        | 0    |      |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |      |

___



**Step - 4 :** Perform linear and non-linear transformation of hidden layer activation at output layer : **_output_layer_input = matrix_dot_product (hidden_layer_activations * wout ) + bout ; output = sigmoid(output_layer_input)_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.23 | 0.49 | 0.83   | 1    |      |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.54 |      | 0.85   | 1    |      |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.82 |      | 0.85   | 0    |      |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |      |

___



**Step - 5 :** Calculate gradient of Error(E) at output layer : **_*E = y-output*_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E     |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.23 | 0.49 | 0.83   | 1    | 0.17  |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.54 |      | 0.85   | 1    | 0.15  |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.82 |      | 0.85   | 0    | -0.85 |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |       |

___



**Step - 6 :**  Compute slope at output and hidden layer : **_*Slope_output_layer= derivatives_sigmoid(output)* 
*Slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)*_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E     |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.23 | 0.49 | 0.83   | 1    | 0.17  |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.54 |      | 0.85   | 1    | 0.15  |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.82 |      | 0.85   | 0    | -0.85 |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer |
| ------------------ | ---- | ---- | ------------------ |
| 0.22               | 0.24 | 0.21 | 0.14               |
| 0.21               | 0.17 | 0.15 | 0.13               |
| 0.2                | 0.18 | 0.13 | 0.13               |

___



**Step - 7 :**  Compute delta at output layer : **_delta_output = E \* slope_output_layer_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E     |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.23 | 0.49 | 0.83   | 1    | 0.17  |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.54 |      | 0.85   | 1    | 0.15  |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.82 |      | 0.85   | 0    | -0.85 |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer |
| ------------------ | ---- | ---- | ------------------ |
| 0.22               | 0.24 | 0.21 | 0.14               |
| 0.21               | 0.17 | 0.15 | 0.13               |
| 0.2                | 0.18 | 0.13 | 0.13               |

| Delta_output |
| ------------ |
| 0.02         |
| 0.01         |
| -0.11        |

____



**Step - 8 :**  Calculate Error at hidden layer : **_Error_at_hidden_layer = matrix_dot_product(d_output, wout.Transpose)_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E     |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.23 | 0.49 | 0.83   | 1    | 0.17  |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.54 |      | 0.85   | 1    | 0.15  |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.82 |      | 0.85   | 0    | -0.85 |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Error_at_hidden_layer |         |         | Slope_output_layer |
| ------------------ | ---- | ---- | --------------------- | ------- | ------- | ------------------ |
| 0.22               | 0.24 | 0.21 | 0.0046                | 0.0108  | 0.0164  | 0.14               |
| 0.21               | 0.17 | 0.15 | 0.0023                | 0.0054  | 0.0082  | 0.13               |
| 0.2                | 0.18 | 0.13 | -0.0253               | -0.0594 | -0.0902 | 0.13               |

| Delta_output |
| ------------ |
| 0.02         |
| 0.01         |
| -0.11        |

___



**Step - 9 :**  Compute delta at hidden layer : **_*Delta_hidden_layer = Error_at_hidden_layer \* slope_hidden_layer*_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E     |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.23 | 0.49 | 0.83   | 1    | 0.17  |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.54 |      | 0.85   | 1    | 0.15  |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.82 |      | 0.85   | 0    | -0.85 |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Error_at_hidden_layer |         |         | Slope_output_layer |
| ------------------ | ---- | ---- | --------------------- | ------- | ------- | ------------------ |
| 0.22               | 0.24 | 0.21 | 0.0046                | 0.0108  | 0.0164  | 0.14               |
| 0.21               | 0.17 | 0.15 | 0.0023                | 0.0054  | 0.0082  | 0.13               |
| 0.2                | 0.18 | 0.13 | -0.0253               | -0.0594 | -0.0902 | 0.13               |

| Delta_hidden_layer |         |         | Delta_output |
| ------------------ | ------- | ------- | ------------ |
| 0.001              | 0.0026  | 0.0034  | 0.02         |
| 0.0005             | 0.0009  | 0.0012  | 0.01         |
| -0.005             | -0.0107 | -0.0117 | -0.11        |

___



**Step - 10 :**  Update weight at both output and hidden layer : **_wout = wout + matrix_dot_product(hiddenlayer_activations.Transpose, d_output)*learning_rate ; 
wh =  wh+ matrix_dot_product(X.Transpose,d_hiddenlayer)*learning_rate_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E     |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.22 | 0.49 | 0.83   | 1    | 0.17  |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.53 |      | 0.85   | 1    | 0.15  |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.81 |      | 0.85   | 0    | -0.85 |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Error_at_hidden_layer |         |         | Slope_output_layer |
| ------------------ | ---- | ---- | --------------------- | ------- | ------- | ------------------ |
| 0.22               | 0.24 | 0.21 | 0.0046                | 0.0108  | 0.0164  | 0.14               |
| 0.21               | 0.17 | 0.15 | 0.0023                | 0.0054  | 0.0082  | 0.13               |
| 0.2                | 0.18 | 0.13 | -0.0253               | -0.0594 | -0.0902 | 0.13               |

| Delta_hidden_layer |         |         | Delta_output | learning_rate |
| ------------------ | ------- | ------- | ------------ | ------------- |
| 0.001              | 0.0026  | 0.0034  | 0.02         | 0.1           |
| 0.0005             | 0.0009  | 0.0012  | 0.01         |               |
| -0.005             | -0.0107 | -0.0117 | -0.11        |               |

____



**Step - 11 :**  Update biases at both output and hidden layer : **_*bh = bh + sum(d_hiddenlayer, axis=0) \* learning_rate*
*bout = bout + sum(d_output, axis=0)\*learning_rate*_**

| x    |      |      |      | wh   |      |      | bh   |      |      | hidden_layer_input |      |      | hidden_layer_activations |      |      | wout | bout | output | y    | E     |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ------------------------ | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1    | 0    | 1    | 0    | 0.13 | 0.14 | 0.16 | 0.28 | 0.19 | 0.2  | 0.72               | 0.51 | 0.87 | 0.67                     | 0.62 | 0.7  | 0.22 | 0.47 | 0.83   | 1    | 0.17  |
| 1    | 0    | 1    | 1    | 0.54 | 0.21 | 0.87 |      |      |      | 0.83               | 1.24 | 1.49 | 0.7                      | 0.78 | 0.82 | 0.53 |      | 0.85   | 1    | 0.15  |
| 0    | 1    | 0    | 1    | 0.31 | 0.18 | 0.51 |      |      |      | 0.93               | 1.13 | 1.69 | 0.72                     | 0.76 | 0.84 | 0.81 |      | 0.85   | 0    | -0.85 |
|      |      |      |      | 0.11 | 0.73 | 0.62 |      |      |      |                    |      |      |                          |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Error_at_hidden_layer |         |         | Slope_output_layer |
| ------------------ | ---- | ---- | --------------------- | ------- | ------- | ------------------ |
| 0.22               | 0.24 | 0.21 | 0.0046                | 0.0108  | 0.0164  | 0.14               |
| 0.21               | 0.17 | 0.15 | 0.0023                | 0.0054  | 0.0082  | 0.13               |
| 0.2                | 0.18 | 0.13 | -0.0253               | -0.0594 | -0.0902 | 0.13               |

| Delta_hidden_layer |         |         | Delta_output | learning_rate |
| ------------------ | ------- | ------- | ------------ | ------------- |
| 0.001              | 0.0026  | 0.0034  | 0.02         | 0.1           |
| 0.0005             | 0.0009  | 0.0012  | 0.01         |               |
| -0.005             | -0.0107 | -0.0117 | -0.11        |               |

___

### Comments

- All the values are rounded to 2 decimal places except Error_at_hidden_layer and Delta_hidden_layer to 4 decimal places as they were too small.
- As the other values were approximated to 2 decimal places there is no much change seen during Step 10 & 11.
- As the heading Could not be merged in markdown the first column has the heading and the merged cells are left blank.